Hello,

Rupert here from [Unternet](https://unternet.co). The future of human-computer interaction is increasingly looking like agents using software alongside the user, allowing people to be more empowered, work faster, and interact more naturally with their computers. That's great, but right now we're still in the age of legacy applications (graphical & feature rich, but dumb and rigid), and text-based chat (intellgent and flexible, but very limited).

With the community here, we want to build a richer interaction layer for language models – so you can query locations and see them on a map, or search for tickets to a ballgame and complete the purchase in the same flow.

And, we want to build this at the scale of the open web – if anyone can build these and host them, and any client can integrate them, we can create a web of capabilities that any intelligent system can use, without being tied to a single proprietary model or ecosystem.

My first approximation of this is Web Applets ([repo with guide to get started here](https://github.com/unternet-co/web-applets)), which is a spec & SDK to make it super easy to build this kind of modular software. I'd love your feedback on this, and contributions to its direction.

This has been a vision technologists have been pursuing since Apple’s Knowledge Navigator and Ada Lovelace’s writing about intelligence machines. It’s vital that this next phase is not one in which the biggest players get to dictate the rules and own the platform, but rather an open one in which anyone can participate and build.

We’ve done it before with the web, and we can do it again.

Thanks for being part of the journey. Play with the tools, create some applets, and send an email to this list to tell me what you think can be improved.

Rupert
